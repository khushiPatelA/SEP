from xgboost import XGBClassifier
from sklearn.metrics import accuracy_score, confusion_matrix

# Define the XGBoost model with the best hyperparameters from Grid Search
xgb_model_optimized = XGBClassifier(
    use_label_encoder=False,
    eval_metric='logloss',
    colsample_bytree=1.0,
    gamma=0.01,
    learning_rate=0.1,
    max_depth=9,
    min_child_weight=1,
    n_estimators=1000,
    subsample=0.6, #CHANGE THIS 
)

# Train the optimized XGBoost model on the reduced dataset with top 14 features
xgb_model_optimized.fit(X_train_new, y_train_new)

# Make predictions on the test set using the optimized model
y_pred_optimized = xgb_model_optimized.predict(X_test_new)

# Evaluate the optimized model using accuracy
test_accuracy_optimized = accuracy_score(y_test_new, y_pred_optimized)
print("Test Accuracy (Optimized):", test_accuracy_optimized)

# Print the confusion matrix for the optimized model
conf_matrix_optimized = confusion_matrix(y_test_new, y_pred_optimized)
print("Confusion Matrix (Optimized):\n", conf_matrix_optimized)
