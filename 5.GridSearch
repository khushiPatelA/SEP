#origion and add ons
from xgboost import XGBClassifier
from sklearn.model_selection import GridSearchCV

# Define the XGBoost model (already fitted on top 14 features)
xgb_model_top14 = XGBClassifier(use_label_encoder=False, eval_metric='logloss')

# Define the parameter grid for hyperparameter tuning
param_grid = {
    'n_estimators': [50, 100, 200],              # Number of trees
    'max_depth': [3, 5, 7],                      # Maximum depth of a tree
    'learning_rate': [0.01, 0.1, 0.2],           # Step size shrinkage (eta)
    'subsample': [0.6, 0.8, 1.0],                # Subsample ratio of the training instances
    'colsample_bytree': [0.6, 0.8, 1.0],         # Subsample ratio of columns when constructing each tree
    'gamma': [0, 0.1, 0.2],                      # Minimum loss reduction required to make a further partition on a leaf node
    'min_child_weight': [1, 3, 5],                # Minimum sum of instance weight (hessian) needed in a child
    'reg_alpha': [0, 0.1, 0.5, 1.0],             # L1 regularization term on weights (Lasso)
    'reg_lambda': [0.5, 1.0, 1.5, 2.0],          # L2 regularization term on weights (Ridge)
    'alpha': [0, 0.1, 0.5, 1.0],                 # XGBoost's regularization term
    'eta': [0.01, 0.1, 0.2, 0.3]                 # Learning rate (same as 'learning_rate')
}


# Set up Grid Search with cross-validation
grid_search = GridSearchCV(estimator=xgb_model_top14, 
                           param_grid=param_grid, 
                           scoring='f1',  
                           cv=5,                # 5-fold cross-validation
                           verbose=2,           # Verbosity level (can be adjusted)
                           n_jobs=-1)           # Use all available cores for parallel processing

# Fit the Grid Search to the training data
grid_search.fit(X_train_new, y_train_new)

# Print the best hyperparameters found by Grid Search
print("Best Hyperparameters:", grid_search.best_params_)

# Print the best score achieved during the search
print("Best Cross-validation Score:", grid_search.best_score_)
                                
# Use the best estimator to make predictions on the test set
best_model = grid_search.best_estimator_
y_pred = best_model.predict(X_test_new)

# Optionally: Evaluate the model using additional metrics (e.g., accuracy, confusion matrix)
from sklearn.metrics import accuracy_score, confusion_matrix

# Evaluate accuracy
accuracy = accuracy_score(y_test_new, y_pred)
print("Test Accuracy:", accuracy)

# Print confusion matrix
conf_matrix = confusion_matrix(y_test_new, y_pred)
print("Confusion Matrix:\n", conf_matrix)
